{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"},{"sourceId":7392733,"sourceType":"datasetVersion","datasetId":4297749},{"sourceId":7465251,"sourceType":"datasetVersion","datasetId":4317718}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"'''\nTo do: \n++++++++++++++++++++++++++++++++++++++++++++++++++++\n- continue training when training is interupted\n- modify the transformer to better process time series/eeg\n- do a scaling stduy on this dataset if possible\n- hyperparameter tuning \n\n\n'''","metadata":{"execution":{"iopub.status.busy":"2024-07-20T02:26:30.891525Z","iopub.execute_input":"2024-07-20T02:26:30.891911Z","iopub.status.idle":"2024-07-20T02:26:30.907363Z","shell.execute_reply.started":"2024-07-20T02:26:30.891880Z","shell.execute_reply":"2024-07-20T02:26:30.906305Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'\\nTo do: \\n++++++++++++++++++++++++++++++++++++++++++++++++++++\\n- continue training when training is interupted\\n- modify the transformer to better process time series/eeg\\n- do a scaling stduy on this dataset if possible\\n- hyperparameter tuning \\n\\n\\n'"},"metadata":{}}]},{"cell_type":"code","source":"import gc\nimport math\nimport matplotlib.pyplot as plt\nimport multiprocessing\nimport numpy as np\nimport os\nimport pandas as pd\nimport random\nimport time\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom glob import glob\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import OneCycleLR\nfrom tqdm.notebook import tqdm\nfrom typing import Dict, List\n\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint('Using', torch.cuda.device_count(), 'GPU(s)')\n!mkdir models","metadata":{"execution":{"iopub.status.busy":"2024-07-20T02:28:01.401228Z","iopub.execute_input":"2024-07-20T02:28:01.402107Z","iopub.status.idle":"2024-07-20T02:28:06.716816Z","shell.execute_reply.started":"2024-07-20T02:28:01.402073Z","shell.execute_reply":"2024-07-20T02:28:06.715546Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Using 1 GPU(s)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.mkdir('/kaggle/working/models')","metadata":{"execution":{"iopub.status.busy":"2024-07-20T02:30:47.332166Z","iopub.execute_input":"2024-07-20T02:30:47.332543Z","iopub.status.idle":"2024-07-20T02:30:47.337638Z","shell.execute_reply.started":"2024-07-20T02:30:47.332512Z","shell.execute_reply":"2024-07-20T02:30:47.336588Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch\na = torch.tensor([1])\ntorch.save(a, '/kaggle/working/models/a')","metadata":{"execution":{"iopub.status.busy":"2024-07-20T02:30:56.702547Z","iopub.execute_input":"2024-07-20T02:30:56.703247Z","iopub.status.idle":"2024-07-20T02:30:56.710150Z","shell.execute_reply.started":"2024-07-20T02:30:56.703216Z","shell.execute_reply":"2024-07-20T02:30:56.709221Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Configuration</b><a class='anchor' id='configuration'></a> [↑](#top) \n\n***","metadata":{}},{"cell_type":"code","source":"class config:\n    AMP = True\n    BATCH_SIZE_TRAIN = 5\n    BATCH_SIZE_VALID = 5\n    EPOCHS = 5\n    FOLDS = 5\n    GRADIENT_ACCUMULATION_STEPS = 4\n    MAX_GRAD_NORM = 1e7\n    NUM_WORKERS = 0 # multiprocessing.cpu_count()\n    PRINT_FREQ = 20\n    SEED = 20\n    TRAIN_FULL_DATA = False\n    VISUALIZE = True\n    WEIGHT_DECAY = 0.01\n    \n    \nclass paths:\n    OUTPUT_DIR = \"/kaggle/working/\"\n    TRAIN_CSV = \"/kaggle/input/hms-harmful-brain-activity-classification/train.csv\"\n    TRAIN_EEGS = \"/kaggle/input/hms-harmful-brain-activity-classification/train_eegs/\"","metadata":{"execution":{"iopub.status.busy":"2024-07-20T02:19:26.735112Z","iopub.execute_input":"2024-07-20T02:19:26.735777Z","iopub.status.idle":"2024-07-20T02:19:26.743282Z","shell.execute_reply.started":"2024-07-20T02:19:26.735748Z","shell.execute_reply":"2024-07-20T02:19:26.742519Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Utils</b><a class='anchor' id='utils'></a> [↑](#top) \n\n***\n\nUtility functions.","metadata":{}},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef asMinutes(s: float):\n    \"Convert to minutes.\"\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since: float, percent: float):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\n\ndef get_logger(filename=paths.OUTPUT_DIR):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\ndef eeg_from_parquet(parquet_path: str, display: bool = False) -> np.ndarray:\n    \"\"\"\n    This function reads a parquet file and extracts the middle 50 seconds of readings. Then it fills NaN values\n    with the mean value (ignoring NaNs).\n    :param parquet_path: path to parquet file.\n    :param display: whether to display EEG plots or not.\n    :return data: np.array of shape  (time_steps, eeg_features) -> (10_000, 8)\n    \"\"\"\n    # === Extract middle 50 seconds ===\n    eeg = pd.read_parquet(parquet_path, columns=eeg_features)\n    rows = len(eeg)\n    offset = (rows - 10_000) // 2 # 50 * 200 = 10_000\n    eeg = eeg.iloc[offset:offset+10_000] # middle 50 seconds, has the same amount of readings to left and right\n    if display: \n        plt.figure(figsize=(10,5))\n        offset = 0\n    # === Convert to numpy ===\n    data = np.zeros((10_000, len(eeg_features))) # create placeholder of same shape with zeros\n    for index, feature in enumerate(eeg_features):\n        x = eeg[feature].values.astype('float32') # convert to float32\n        mean = np.nanmean(x) # arithmetic mean along the specified axis, ignoring NaNs\n        nan_percentage = np.isnan(x).mean() # percentage of NaN values in feature\n        # === Fill nan values ===\n        if nan_percentage < 1: # if some values are nan, but not all\n            x = np.nan_to_num(x, nan=mean)\n        else: # if all values are nan\n            x[:] = 0\n        data[:, index] = x\n        if display: \n            if index != 0:\n                offset += x.max()\n            plt.plot(range(10_000), x-offset, label=feature)\n            offset -= x.min()\n    if display:\n        plt.legend()\n        name = parquet_path.split('/')[-1].split('.')[0]\n        plt.yticks([])\n        plt.title(f'EEG {name}',size=16)\n        plt.show()    \n    return data\n\n\ndef seed_everything(seed: int):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed) \n    \n    \ndef sep():\n    print(\"-\"*100)\n\n    \ntarget_preds = [x + \"_pred\" for x in ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']]\nlabel_to_num = {'Seizure': 0, 'LPD': 1, 'GPD': 2, 'LRDA': 3, 'GRDA': 4, 'Other':5}\nnum_to_label = {v: k for k, v in label_to_num.items()}\nLOGGER = get_logger()\nseed_everything(config.SEED)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-20T02:19:26.744693Z","iopub.execute_input":"2024-07-20T02:19:26.745065Z","iopub.status.idle":"2024-07-20T02:19:26.768955Z","shell.execute_reply.started":"2024-07-20T02:19:26.745041Z","shell.execute_reply":"2024-07-20T02:19:26.768089Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Load Data</b><a class='anchor' id='load_data'></a> [↑](#top) \n\n***\n\nLoad the competition's data.","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(paths.TRAIN_CSV)\nlabel_cols = train_df.columns[-6:]\nprint(f\"Train cataframe shape is: {train_df.shape}\")\nprint(f\"Labels: {list(label_cols)}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-20T02:19:26.771362Z","iopub.execute_input":"2024-07-20T02:19:26.771791Z","iopub.status.idle":"2024-07-20T02:19:27.026392Z","shell.execute_reply.started":"2024-07-20T02:19:26.771756Z","shell.execute_reply":"2024-07-20T02:19:27.025416Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Train cataframe shape is: (106800, 15)\nLabels: ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n","output_type":"stream"}]},{"cell_type":"code","source":"eeg_df = pd.read_parquet(paths.TRAIN_EEGS + \"100261680.parquet\")\neeg_features = eeg_df.columns\nprint(f'There are {len(eeg_features)} raw eeg features')\nprint(list(eeg_features))\neeg_features = ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\nfeature_to_index = {x:y for x,y in zip(eeg_features, range(len(eeg_features)))}","metadata":{"execution":{"iopub.status.busy":"2024-07-20T02:19:27.027683Z","iopub.execute_input":"2024-07-20T02:19:27.027996Z","iopub.status.idle":"2024-07-20T02:19:27.311619Z","shell.execute_reply.started":"2024-07-20T02:19:27.027970Z","shell.execute_reply":"2024-07-20T02:19:27.310650Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"There are 20 raw eeg features\n['Fp1', 'F3', 'C3', 'P3', 'F7', 'T3', 'T5', 'O1', 'Fz', 'Cz', 'Pz', 'Fp2', 'F4', 'C4', 'P4', 'F8', 'T4', 'T6', 'O2', 'EKG']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### <b><span style='color:#F1A424'>Read all EEG parquets</span></b>","metadata":{}},{"cell_type":"code","source":"all_eegs = np.load('/kaggle/input/brain-eegs/eegs.npy',allow_pickle=True).item()","metadata":{"execution":{"iopub.status.busy":"2024-07-20T02:19:27.312784Z","iopub.execute_input":"2024-07-20T02:19:27.313090Z","iopub.status.idle":"2024-07-20T02:21:42.983563Z","shell.execute_reply.started":"2024-07-20T02:19:27.313065Z","shell.execute_reply":"2024-07-20T02:21:42.982371Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"%%time\n\nCREATE_EEGS = False\nvisualize = 1\neeg_paths = glob(paths.TRAIN_EEGS + \"*.parquet\")\neeg_ids = train_df.eeg_id.unique()","metadata":{"execution":{"iopub.status.busy":"2024-07-20T02:21:42.984955Z","iopub.execute_input":"2024-07-20T02:21:42.985282Z","iopub.status.idle":"2024-07-20T02:21:45.592092Z","shell.execute_reply.started":"2024-07-20T02:21:42.985256Z","shell.execute_reply":"2024-07-20T02:21:45.591073Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"CPU times: user 65.4 ms, sys: 6.64 ms, total: 72 ms\nWall time: 2.6 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Data pre-processing</b><a class='anchor' id='preprocessing'></a> [↑](#top) \n\n***","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(paths.TRAIN_CSV)\nlabel_cols = df.columns[-6:]\n\ntrain_df = df.groupby('eeg_id')[['patient_id']].agg('first')\naux = df.groupby('eeg_id')[label_cols].agg('sum') \n\nfor label in label_cols:\n    train_df[label] = aux[label].values\n    \ny_data = train_df[label_cols].values\ny_data = y_data / y_data.sum(axis=1,keepdims=True)\ntrain_df[label_cols] = y_data\n\naux = df.groupby('eeg_id')[['expert_consensus']].agg('first')\ntrain_df['target'] = aux\n\ntrain_df = train_df.reset_index()\ntrain_df = train_df.loc[train_df.eeg_id.isin(eeg_ids)]\nprint(f\"Train dataframe with unique eeg_id has shape: {train_df.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-20T02:21:45.593170Z","iopub.execute_input":"2024-07-20T02:21:45.593457Z","iopub.status.idle":"2024-07-20T02:21:45.836186Z","shell.execute_reply.started":"2024-07-20T02:21:45.593432Z","shell.execute_reply":"2024-07-20T02:21:45.835233Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Train dataframe with unique eeg_id has shape: (17089, 9)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Validation</b><a class='anchor' id='validation'></a> [↑](#top) \n\n***\n\nWe train using `GroupKFold` on `patient_id`.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold, GroupKFold\n\n\ngkf = GroupKFold(n_splits=config.FOLDS)\nfor fold, (train_index, valid_index) in enumerate(gkf.split(train_df, train_df.target, train_df.patient_id)):\n    train_df.loc[valid_index, \"fold\"] = int(fold)\n    \ndisplay(train_df.groupby('fold').size()), sep()","metadata":{"execution":{"iopub.status.busy":"2024-07-20T02:21:45.837390Z","iopub.execute_input":"2024-07-20T02:21:45.837700Z","iopub.status.idle":"2024-07-20T02:21:45.869278Z","shell.execute_reply.started":"2024-07-20T02:21:45.837673Z","shell.execute_reply":"2024-07-20T02:21:45.868446Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"fold\n0.0    3418\n1.0    3418\n2.0    3418\n3.0    3418\n4.0    3417\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"----------------------------------------------------------------------------------------------------\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(None, None)"},"metadata":{}}]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Butter Low-Pass Filter</b><a class='anchor' id='filter'></a> [↑](#top) \n\n***\n\n- [scipy.signal.butter()][1]\n- [scipy.signal.lfilter()][2]\n\n[1]: https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.butter.html#scipy.signal.butter\n[2]: https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.lfilter.html#scipy.signal.lfilter","metadata":{}},{"cell_type":"code","source":"from scipy.signal import butter, lfilter\n\ndef butter_lowpass_filter(data, cutoff_freq: int = 20, sampling_rate: int = 200, order: int = 4):\n    nyquist = 0.5 * sampling_rate\n    normal_cutoff = cutoff_freq / nyquist\n    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n    filtered_data = lfilter(b, a, data, axis=0)\n    return filtered_data","metadata":{"execution":{"iopub.status.busy":"2024-07-20T02:21:45.873613Z","iopub.execute_input":"2024-07-20T02:21:45.873973Z","iopub.status.idle":"2024-07-20T02:21:45.935519Z","shell.execute_reply.started":"2024-07-20T02:21:45.873949Z","shell.execute_reply":"2024-07-20T02:21:45.934609Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## <b><span style='color:#F1A424'>Visualize</span></b>\n","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(\n        self, df: pd.DataFrame, config, mode: str = 'train',\n        eegs: Dict[int, np.ndarray] = all_eegs, downsample: int = 5\n    ): \n        self.df = df\n        self.config = config\n        self.batch_size = self.config.BATCH_SIZE_TRAIN\n        self.mode = mode\n        self.eegs = eegs\n        self.downsample = downsample\n        \n    def __len__(self):\n        \"\"\"\n        Length of dataset.\n        \"\"\"\n        return len(self.df)\n        \n    def __getitem__(self, index):\n        \"\"\"\n        Get one item.\n        \"\"\"\n        X, y = self.__data_generation(index)\n        \n        X = X[::self.downsample,:] # used to split the 10000 eeg to 2000 mini samples \n        # that was sequence[start:stop:step]\n        \n        output = {\n            \"X\": torch.tensor(X, dtype=torch.float32),\n            \"y\": torch.tensor(y, dtype=torch.float32)\n        }\n        return output\n                        \n    def __data_generation(self, index):\n        row = self.df.iloc[index]\n        X = np.zeros((10_000, 8), dtype='float32')\n        y = np.zeros(6, dtype='float32')\n        data = self.eegs[row.eeg_id]\n\n        # === Feature engineering ===\n        X[:,0] = data[:,feature_to_index['Fp1']] - data[:,feature_to_index['T3']]\n        X[:,1] = data[:,feature_to_index['T3']] - data[:,feature_to_index['O1']]\n\n        X[:,2] = data[:,feature_to_index['Fp1']] - data[:,feature_to_index['C3']]\n        X[:,3] = data[:,feature_to_index['C3']] - data[:,feature_to_index['O1']]\n\n        X[:,4] = data[:,feature_to_index['Fp2']] - data[:,feature_to_index['C4']]\n        X[:,5] = data[:,feature_to_index['C4']] - data[:,feature_to_index['O2']]\n\n        X[:,6] = data[:,feature_to_index['Fp2']] - data[:,feature_to_index['T4']]\n        X[:,7] = data[:,feature_to_index['T4']] - data[:,feature_to_index['O2']]\n\n        # === Standarize === but why these values??\n        X = np.clip(X,-1024, 1024)\n        X = np.nan_to_num(X, nan=0) / 32.0\n\n        # === Butter Low-pass Filter ===\n        X = butter_lowpass_filter(X)\n        \n        if self.mode != 'test':\n            y = row[label_cols].values.astype(np.float32)\n            \n        return X, y","metadata":{"execution":{"iopub.status.busy":"2024-07-20T02:21:45.936782Z","iopub.execute_input":"2024-07-20T02:21:45.937051Z","iopub.status.idle":"2024-07-20T02:21:45.950932Z","shell.execute_reply.started":"2024-07-20T02:21:45.937028Z","shell.execute_reply":"2024-07-20T02:21:45.950066Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> DataLoader</b><a class='anchor' id='dataloader'></a> [↑](#top) \n\n***","metadata":{}},{"cell_type":"code","source":"config.BATCH_SIZE_TRAIN","metadata":{"execution":{"iopub.status.busy":"2024-07-20T02:21:45.951972Z","iopub.execute_input":"2024-07-20T02:21:45.952277Z","iopub.status.idle":"2024-07-20T02:21:45.963688Z","shell.execute_reply.started":"2024-07-20T02:21:45.952253Z","shell.execute_reply":"2024-07-20T02:21:45.962868Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"5"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = CustomDataset(train_df, config, mode=\"train\")\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=config.BATCH_SIZE_TRAIN,\n    shuffle=False,\n    num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True\n)\noutput = train_dataset[0]\nX, y = output[\"X\"], output[\"y\"]\nprint(f\"X shape: {X.shape}\")\nprint(f\"y shape: {y.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-20T02:21:45.964875Z","iopub.execute_input":"2024-07-20T02:21:45.965274Z","iopub.status.idle":"2024-07-20T02:21:46.007131Z","shell.execute_reply.started":"2024-07-20T02:21:45.965248Z","shell.execute_reply":"2024-07-20T02:21:46.006275Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"X shape: torch.Size([2000, 8])\ny shape: torch.Size([6])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"from torch import nn, Tensor\nfrom torch.nn import TransformerEncoder, TransformerEncoderLayer\nfrom torchinfo import summary\n\nclass eegEncoder(nn.Module):\n    \n\n    def __init__(self,d_model, nhead,  nlayers, nclasses, d_hid, dropout=0.1):\n        super(eegEncoder, self).__init__()\n        self.d_model = d_model\n        self.input_projection = nn.Linear(8, d_model) # (n_chhannels, d_model)  \n        self.linear = nn.Linear(d_model, nclasses)\n\n        \n        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout, batch_first=True, norm_first =False) # set batch_first = True b/c input is of shape (b, T, C)!!!!!!!\n        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n    \n    def pos_encode(self, encoding_1):\n        pe = torch.ones_like(encoding_1[0])\n        position = torch.arange(0, 2000).unsqueeze(-1)\n        temp = torch.Tensor(range(0, self.d_model, 2))\n        temp = temp * -(math.log(10000) / self.d_model)\n        temp = torch.exp(temp).unsqueeze(0)\n        temp = torch.matmul(position.float(), temp)  # shape:[input, d_model/2]\n        pe[:, 0::2] = torch.sin(temp)\n        pe[:, 1::2] = torch.cos(temp)\n\n    \n        encoding_1 = encoding_1 + pe\n        return encoding_1\n\n    def forward(self, src):\n        \n        B, T, C = src.shape #where B = batch_size, T = time_step, C = n_classes\n        \n        input_proj = self.input_projection(src) #output is shape (B, T, d_model)\n        input_pos = self.pos_encode(input_proj)#self.position_embedding_table(torch.arange(T, device=src.device))  # (T, n_embd)\n        \n        output_1 = self.transformer_encoder(input_pos) #output_1 is shape of (B,T, )\n    \n        #print(output_1.shape)\n        \n        output_2 = torch.mean(output_1, axis=1) #average over sequence length dimension. Output is shape (B,)\n        output_2 = self.linear(output_2)\n                \n        return output_2\n\n# def __init__(self,d_model, nhead,  nlayers, nclasses, d_hid, dropout=0.1):\nmodel = eegEncoder(d_model = 640, nhead= 8, nlayers= 10, nclasses = 6, d_hid=1024)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T02:21:46.008521Z","iopub.execute_input":"2024-07-20T02:21:46.008816Z","iopub.status.idle":"2024-07-20T02:21:46.115846Z","shell.execute_reply.started":"2024-07-20T02:21:46.008793Z","shell.execute_reply":"2024-07-20T02:21:46.114788Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model2 = eegEncoder(d_model = 640, nhead= 8, nlayers= 10, nclasses = 6, d_hid=1024)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T02:21:46.117420Z","iopub.execute_input":"2024-07-20T02:21:46.117760Z","iopub.status.idle":"2024-07-20T02:21:46.197444Z","shell.execute_reply.started":"2024-07-20T02:21:46.117733Z","shell.execute_reply":"2024-07-20T02:21:46.196630Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"#model= nn.DataParallel(model)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T02:21:46.198669Z","iopub.execute_input":"2024-07-20T02:21:46.199099Z","iopub.status.idle":"2024-07-20T02:21:46.358395Z","shell.execute_reply.started":"2024-07-20T02:21:46.199065Z","shell.execute_reply":"2024-07-20T02:21:46.357510Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"eegEncoder(\n  (input_projection): Linear(in_features=8, out_features=640, bias=True)\n  (linear): Linear(in_features=640, out_features=6, bias=True)\n  (transformer_encoder): TransformerEncoder(\n    (layers): ModuleList(\n      (0-9): 10 x TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=640, out_features=640, bias=True)\n        )\n        (linear1): Linear(in_features=640, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=1024, out_features=640, bias=True)\n        (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"summary(model)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T02:21:46.359598Z","iopub.execute_input":"2024-07-20T02:21:46.359955Z","iopub.status.idle":"2024-07-20T02:21:46.378358Z","shell.execute_reply.started":"2024-07-20T02:21:46.359928Z","shell.execute_reply":"2024-07-20T02:21:46.377396Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                                            Param #\n==========================================================================================\neegEncoder                                                        --\n├─Linear: 1-1                                                     5,760\n├─Linear: 1-2                                                     3,846\n├─TransformerEncoder: 1-3                                         --\n│    └─ModuleList: 2-1                                            --\n│    │    └─TransformerEncoderLayer: 3-1                          2,955,904\n│    │    └─TransformerEncoderLayer: 3-2                          2,955,904\n│    │    └─TransformerEncoderLayer: 3-3                          2,955,904\n│    │    └─TransformerEncoderLayer: 3-4                          2,955,904\n│    │    └─TransformerEncoderLayer: 3-5                          2,955,904\n│    │    └─TransformerEncoderLayer: 3-6                          2,955,904\n│    │    └─TransformerEncoderLayer: 3-7                          2,955,904\n│    │    └─TransformerEncoderLayer: 3-8                          2,955,904\n│    │    └─TransformerEncoderLayer: 3-9                          2,955,904\n│    │    └─TransformerEncoderLayer: 3-10                         2,955,904\n==========================================================================================\nTotal params: 29,568,646\nTrainable params: 29,568,646\nNon-trainable params: 0\n=========================================================================================="},"metadata":{}}]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Train and Validation Functions</b><a class='anchor' id='functions'></a> [↑](#top) \n\n***","metadata":{}},{"cell_type":"code","source":"def train_epoch(train_loader, model, optimizer, epoch, scheduler, device):\n    \"\"\"One epoch training pass.\"\"\"\n    model.train()\n    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n    scaler = torch.cuda.amp.GradScaler(enabled=config.AMP)\n    losses = AverageMeter()\n    start = end = time.time()\n    global_step = 0\n    \n    # ========== ITERATE OVER TRAIN BATCHES ============\n    with tqdm(train_loader, unit=\"train_batch\", desc='Train') as tqdm_train_loader:\n        for step, batch in enumerate(tqdm_train_loader):\n            X = batch.pop(\"X\").to(device) # send inputs to `device`\n            \n            \n            \n            y = batch.pop(\"y\").to(device) # send labels to `device`\n            batch_size = y.size(0)\n            \n            with torch.cuda.amp.autocast(enabled=config.AMP):\n                y_preds = model(X)\n                loss = criterion(F.log_softmax(y_preds, dim=1), y)\n            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n                \n            losses.update(loss.item(), batch_size)\n            scaler.scale(loss).backward()\n            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.MAX_GRAD_NORM)\n            \n            if (step + 1) % config.GRADIENT_ACCUMULATION_STEPS == 0:\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n                global_step += 1\n                scheduler.step()\n            end = time.time()\n\n            # ========== LOG INFO ==========\n            if step % config.PRINT_FREQ == 0 or step == (len(train_loader)-1):\n                print('Epoch: [{0}][{1}/{2}] '\n                      'Elapsed {remain:s} '\n                      'Loss: {loss.avg:.4f} '\n                      'Grad: {grad_norm:.4f}  '\n                      'LR: {lr:.8f}  '\n                      .format(epoch+1, step, len(train_loader), \n                              remain=timeSince(start, float(step+1)/len(train_loader)),\n                              loss=losses,\n                              grad_norm=grad_norm,\n                              lr=scheduler.get_last_lr()[0]))\n                \n            tqdm_train_loader.set_postfix(loss=loss.item())        \n\n    return losses.avg\n\n\ndef valid_epoch(valid_loader, model, device):\n    model.eval() \n    softmax = nn.Softmax(dim=1)\n    losses = AverageMeter()\n    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n    prediction_dict = {}\n    preds = []\n    start = end = time.time()\n    with tqdm(valid_loader, unit=\"valid_batch\", desc='Validation') as tqdm_valid_loader:\n        for step, batch in enumerate(tqdm_valid_loader):\n            X = batch.pop(\"X\").to(device) \n            y = batch.pop(\"y\").to(device)\n            batch_size = y.size(0)\n            with torch.no_grad():\n                y_preds = model(X)\n                loss = criterion(F.log_softmax(y_preds, dim=1), y)\n            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n            losses.update(loss.item(), batch_size)\n            y_preds = softmax(y_preds)\n            preds.append(y_preds.to('cpu').numpy()) \n            end = time.time()\n\n            # ========== LOG INFO ==========\n            if step % config.PRINT_FREQ == 0 or step == (len(valid_loader)-1):\n                print('EVAL: [{0}/{1}] '\n                      'Elapsed {remain:s} '\n                      'Loss: {loss.avg:.4f} '\n                      .format(step, len(valid_loader),\n                              remain=timeSince(start, float(step+1)/len(valid_loader)),\n                              loss=losses))\n                \n            tqdm_valid_loader.set_postfix(loss=loss.item())    \n                \n    prediction_dict[\"predictions\"] = np.concatenate(preds)\n    return losses.avg, prediction_dict","metadata":{"execution":{"iopub.status.busy":"2024-07-20T02:21:46.379617Z","iopub.execute_input":"2024-07-20T02:21:46.380426Z","iopub.status.idle":"2024-07-20T02:21:46.399724Z","shell.execute_reply.started":"2024-07-20T02:21:46.380392Z","shell.execute_reply":"2024-07-20T02:21:46.398828Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Train Loop</b><a class='anchor' id='train_loop'></a> [↑](#top) \n\n***","metadata":{}},{"cell_type":"code","source":"def train_loop(df, fold):\n    \n    LOGGER.info(f\"========== Fold: {fold} training ==========\")\n\n    # ======== SPLIT ==========\n    train_folds = df[df['fold'] != fold].reset_index(drop=True)\n    valid_folds = df[df['fold'] == fold].reset_index(drop=True)\n    \n    # ======== DATASETS ==========\n    train_dataset = CustomDataset(train_folds, config, mode=\"train\")\n    valid_dataset = CustomDataset(valid_folds, config, mode=\"train\")\n    \n    # ======== DATALOADERS ==========\n    train_loader = DataLoader(train_dataset,\n                              batch_size=config.BATCH_SIZE_TRAIN,\n                              shuffle=True,\n                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset,\n                              batch_size=config.BATCH_SIZE_VALID,\n                              shuffle=False,\n                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=False)\n    \n    # ======== MODEL ==========\n   # model = eegEncoder()\n   # model.to(device)\n\n    optimizer = torch.optim.AdamW(model.parameters(), lr=0.1, weight_decay=config.WEIGHT_DECAY)\n    scheduler = OneCycleLR(\n        optimizer,\n        max_lr=1e-3,\n        epochs=config.EPOCHS,\n        steps_per_epoch=len(train_loader),\n        pct_start=0.1,\n        anneal_strategy=\"cos\",\n        final_div_factor=100,\n    )\n\n    # ======= LOSS ==========\n    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n    \n    best_loss = np.inf\n    # ====== ITERATE EPOCHS ========\n    for epoch in range(config.EPOCHS):\n        start_time = time.time()\n\n        # ======= TRAIN ==========\n        avg_train_loss = train_epoch(train_loader, model, optimizer, epoch, scheduler, device)\n\n        # ======= EVALUATION ==========\n        avg_val_loss, prediction_dict = valid_epoch(valid_loader, model, device)\n        predictions = prediction_dict[\"predictions\"]\n        \n        # ======= SCORING ==========\n        elapsed = time.time() - start_time\n\n        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_train_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        \n        if avg_val_loss < best_loss:\n            best_loss = avg_val_loss\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n            torch.save({'model': model.state_dict(),\n                        'predictions': predictions},\n                         f\"/kaggle/working/models/eegEncoder_{fold}_best.pth\")\n\n    predictions = torch.load(f\"/kaggle/working/models/eegEncoder_{fold}_best.pth\", \n                             map_location=torch.device('cpu'))['predictions']\n    valid_folds[target_preds] = predictions\n\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    return valid_folds","metadata":{"execution":{"iopub.status.busy":"2024-07-20T02:22:58.478057Z","iopub.execute_input":"2024-07-20T02:22:58.478471Z","iopub.status.idle":"2024-07-20T02:22:58.491749Z","shell.execute_reply.started":"2024-07-20T02:22:58.478441Z","shell.execute_reply":"2024-07-20T02:22:58.490765Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Train</b><a class='anchor' id='train'></a> [↑](#top) \n\n***","metadata":{}},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:47:11.777029Z","iopub.execute_input":"2024-07-19T03:47:11.777840Z","iopub.status.idle":"2024-07-19T03:47:11.783374Z","shell.execute_reply.started":"2024-07-19T03:47:11.777809Z","shell.execute_reply":"2024-07-19T03:47:11.782429Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"code","source":"config.EPOCH = 2","metadata":{"execution":{"iopub.status.busy":"2024-07-19T02:55:16.756116Z","iopub.execute_input":"2024-07-19T02:55:16.756512Z","iopub.status.idle":"2024-07-19T02:55:16.760774Z","shell.execute_reply.started":"2024-07-19T02:55:16.756480Z","shell.execute_reply":"2024-07-19T02:55:16.759875Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"def get_result(oof_df):\n    kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n    labels = torch.tensor(oof_df[label_cols].values)\n    preds = torch.tensor(oof_df[target_preds].values)\n    preds = F.log_softmax(preds, dim=1)\n    result = kl_loss(preds, labels)\n    return result\n\nif not config.TRAIN_FULL_DATA:\n    oof_df = pd.DataFrame()\n    for fold in range(config.FOLDS):\n        if fold in [0, 1, 2, 3, 4]:\n            _oof_df = train_loop(train_df, fold)\n            oof_df = pd.concat([oof_df, _oof_df])\n            LOGGER.info(f\"========== Fold {fold} finished ==========\")\n    oof_df = oof_df.reset_index(drop=True)\n    oof_df.to_csv('/kaggle/working/models/oof_df.csv', index=False)\nelse:\n    train_loop_full_data(train_df)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-19T02:55:19.411844Z","iopub.execute_input":"2024-07-19T02:55:19.412541Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"========== Fold: 0 training ==========\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/2734 [00:00<?, ?train_batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31a66162f6304f6b8bd55f6ad95c8514"}},"metadata":{}},{"name":"stdout","text":"Epoch: [1][0/2734] Elapsed 0m 0s (remain 34m 14s) Loss: 0.3596 Grad: 172808.2812  LR: 0.00004000  \nEpoch: [1][20/2734] Elapsed 0m 15s (remain 32m 38s) Loss: 0.3243 Grad: 93456.1562  LR: 0.00004003  \nEpoch: [1][40/2734] Elapsed 0m 29s (remain 32m 21s) Loss: 0.3248 Grad: 89262.7734  LR: 0.00004013  \nEpoch: [1][60/2734] Elapsed 0m 43s (remain 32m 6s) Loss: 0.3267 Grad: 112738.5391  LR: 0.00004029  \nEpoch: [1][80/2734] Elapsed 0m 58s (remain 31m 51s) Loss: 0.3215 Grad: 125759.7891  LR: 0.00004051  \nEpoch: [1][100/2734] Elapsed 1m 12s (remain 31m 36s) Loss: nan Grad: 36435.7891  LR: 0.00004079  \nEpoch: [1][120/2734] Elapsed 1m 27s (remain 31m 22s) Loss: nan Grad: 51478.6680  LR: 0.00004114  \nEpoch: [1][140/2734] Elapsed 1m 41s (remain 31m 8s) Loss: nan Grad: 26736.5410  LR: 0.00004155  \nEpoch: [1][160/2734] Elapsed 1m 56s (remain 30m 54s) Loss: nan Grad: 32762.2539  LR: 0.00004203  \nEpoch: [1][180/2734] Elapsed 2m 10s (remain 30m 39s) Loss: nan Grad: 29484.0000  LR: 0.00004257  \nEpoch: [1][200/2734] Elapsed 2m 24s (remain 30m 25s) Loss: nan Grad: 17810.2812  LR: 0.00004317  \nEpoch: [1][220/2734] Elapsed 2m 39s (remain 30m 11s) Loss: nan Grad: 22947.0449  LR: 0.00004383  \nEpoch: [1][240/2734] Elapsed 2m 53s (remain 29m 57s) Loss: nan Grad: 35126.7305  LR: 0.00004456  \nEpoch: [1][260/2734] Elapsed 3m 8s (remain 29m 42s) Loss: nan Grad: 39863.8398  LR: 0.00004535  \nEpoch: [1][280/2734] Elapsed 3m 22s (remain 29m 28s) Loss: nan Grad: 14839.5850  LR: 0.00004621  \nEpoch: [1][300/2734] Elapsed 3m 37s (remain 29m 14s) Loss: nan Grad: 14011.6680  LR: 0.00004712  \nEpoch: [1][320/2734] Elapsed 3m 51s (remain 28m 59s) Loss: nan Grad: 9650.2422  LR: 0.00004810  \nEpoch: [1][340/2734] Elapsed 4m 5s (remain 28m 45s) Loss: nan Grad: 10221.2725  LR: 0.00004914  \nEpoch: [1][360/2734] Elapsed 4m 20s (remain 28m 30s) Loss: nan Grad: 9303.9785  LR: 0.00005025  \nEpoch: [1][380/2734] Elapsed 4m 34s (remain 28m 16s) Loss: nan Grad: 3468.0205  LR: 0.00005141  \nEpoch: [1][400/2734] Elapsed 4m 49s (remain 28m 1s) Loss: nan Grad: 4162.2363  LR: 0.00005264  \nEpoch: [1][420/2734] Elapsed 5m 3s (remain 27m 47s) Loss: nan Grad: 5719.2017  LR: 0.00005393  \nEpoch: [1][440/2734] Elapsed 5m 17s (remain 27m 33s) Loss: nan Grad: 2538.8625  LR: 0.00005528  \nEpoch: [1][460/2734] Elapsed 5m 32s (remain 27m 18s) Loss: nan Grad: 1936.2216  LR: 0.00005669  \nEpoch: [1][480/2734] Elapsed 5m 46s (remain 27m 4s) Loss: nan Grad: 1871.1117  LR: 0.00005816  \nEpoch: [1][500/2734] Elapsed 6m 1s (remain 26m 49s) Loss: nan Grad: 1900.1930  LR: 0.00005970  \nEpoch: [1][520/2734] Elapsed 6m 15s (remain 26m 35s) Loss: nan Grad: 299.8117  LR: 0.00006129  \nEpoch: [1][540/2734] Elapsed 6m 30s (remain 26m 20s) Loss: nan Grad: 294.8647  LR: 0.00006295  \nEpoch: [1][560/2734] Elapsed 6m 44s (remain 26m 6s) Loss: nan Grad: 333.9366  LR: 0.00006467  \nEpoch: [1][580/2734] Elapsed 6m 58s (remain 25m 52s) Loss: nan Grad: 106.5234  LR: 0.00006644  \nEpoch: [1][600/2734] Elapsed 7m 13s (remain 25m 37s) Loss: nan Grad: 112.4359  LR: 0.00006828  \nEpoch: [1][620/2734] Elapsed 7m 27s (remain 25m 23s) Loss: nan Grad: 91.7362  LR: 0.00007018  \nEpoch: [1][640/2734] Elapsed 7m 42s (remain 25m 9s) Loss: nan Grad: 155.3151  LR: 0.00007213  \nEpoch: [1][660/2734] Elapsed 7m 56s (remain 24m 54s) Loss: nan Grad: 109.3318  LR: 0.00007415  \nEpoch: [1][680/2734] Elapsed 8m 11s (remain 24m 40s) Loss: nan Grad: 98.0590  LR: 0.00007622  \nEpoch: [1][700/2734] Elapsed 8m 25s (remain 24m 26s) Loss: nan Grad: 92.6251  LR: 0.00007835  \nEpoch: [1][720/2734] Elapsed 8m 39s (remain 24m 11s) Loss: nan Grad: 147.8233  LR: 0.00008055  \nEpoch: [1][740/2734] Elapsed 8m 54s (remain 23m 57s) Loss: nan Grad: 92.1625  LR: 0.00008279  \nEpoch: [1][760/2734] Elapsed 9m 8s (remain 23m 42s) Loss: nan Grad: 33.8519  LR: 0.00008510  \nEpoch: [1][780/2734] Elapsed 9m 23s (remain 23m 28s) Loss: nan Grad: 10.4985  LR: 0.00008747  \nEpoch: [1][800/2734] Elapsed 9m 37s (remain 23m 14s) Loss: nan Grad: 3.9186  LR: 0.00008989  \nEpoch: [1][820/2734] Elapsed 9m 52s (remain 22m 59s) Loss: nan Grad: 1.8062  LR: 0.00009237  \nEpoch: [1][840/2734] Elapsed 10m 6s (remain 22m 45s) Loss: nan Grad: 5.5493  LR: 0.00009490  \nEpoch: [1][860/2734] Elapsed 10m 20s (remain 22m 30s) Loss: nan Grad: 3.7873  LR: 0.00009749  \nEpoch: [1][880/2734] Elapsed 10m 35s (remain 22m 16s) Loss: nan Grad: 2.4030  LR: 0.00010014  \nEpoch: [1][900/2734] Elapsed 10m 49s (remain 22m 1s) Loss: nan Grad: 4.6962  LR: 0.00010284  \nEpoch: [1][920/2734] Elapsed 11m 4s (remain 21m 47s) Loss: nan Grad: 5.7893  LR: 0.00010560  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Val ","metadata":{}},{"cell_type":"code","source":"def valid_only(df, fold):\n    valid_folds = df[df['fold'] == fold].reset_index(drop=True)\n    valid_dataset = CustomDataset(valid_folds, config, mode=\"train\")\n    valid_loader = DataLoader(valid_dataset,\n                              batch_size=config.BATCH_SIZE_VALID,\n                              shuffle=False,\n                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=False)\n    \n    for epoch in range(config.EPOCHS):\n        avg_val_loss, prediction_dict = valid_epoch(valid_loader, model, device)\n        predictions = prediction_dict[\"predictions\"]\n    valid_folds[target_preds] = predictions\n    return valid_folds","metadata":{"execution":{"iopub.status.busy":"2024-07-20T02:23:08.101804Z","iopub.execute_input":"2024-07-20T02:23:08.102880Z","iopub.status.idle":"2024-07-20T02:23:08.109070Z","shell.execute_reply.started":"2024-07-20T02:23:08.102842Z","shell.execute_reply":"2024-07-20T02:23:08.108111Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model = torhc.load()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(config.FOLDS):    \n    _oof_df = valid_only(train_df, fold)\n    oof_df = pd.concat([oof_df, _oof_df])\n    LOGGER.info(f\"========== Fold {fold} finished ==========\")\noof_df = oof_df.reset_index(drop=True)\noof_df.to_csv('/kaggle/working/models/oof_df.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T02:23:09.505429Z","iopub.execute_input":"2024-07-20T02:23:09.505814Z","iopub.status.idle":"2024-07-20T02:23:15.486267Z","shell.execute_reply.started":"2024-07-20T02:23:09.505784Z","shell.execute_reply":"2024-07-20T02:23:15.484993Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/684 [00:00<?, ?valid_batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d636b1f715040bb9df52ea48f62548e"}},"metadata":{}},{"name":"stdout","text":"EVAL: [0/684] Elapsed 0m 0s (remain 6m 30s) Loss: 0.5131 \nEVAL: [20/684] Elapsed 0m 5s (remain 2m 49s) Loss: 0.4107 \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mFOLDS):    \n\u001b[0;32m----> 2\u001b[0m     _oof_df \u001b[38;5;241m=\u001b[39m \u001b[43mvalid_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     oof_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([oof_df, _oof_df])\n\u001b[1;32m      4\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m========== Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m finished ==========\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[30], line 10\u001b[0m, in \u001b[0;36mvalid_only\u001b[0;34m(df, fold)\u001b[0m\n\u001b[1;32m      4\u001b[0m valid_loader \u001b[38;5;241m=\u001b[39m DataLoader(valid_dataset,\n\u001b[1;32m      5\u001b[0m                           batch_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mBATCH_SIZE_VALID,\n\u001b[1;32m      6\u001b[0m                           shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m                           num_workers\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mNUM_WORKERS, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mEPOCHS):\n\u001b[0;32m---> 10\u001b[0m     avg_val_loss, prediction_dict \u001b[38;5;241m=\u001b[39m \u001b[43mvalid_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m prediction_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     12\u001b[0m valid_folds[target_preds] \u001b[38;5;241m=\u001b[39m predictions\n","Cell \u001b[0;32mIn[27], line 74\u001b[0m, in \u001b[0;36mvalid_epoch\u001b[0;34m(valid_loader, model, device)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mGRADIENT_ACCUMULATION_STEPS \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     73\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m config\u001b[38;5;241m.\u001b[39mGRADIENT_ACCUMULATION_STEPS\n\u001b[0;32m---> 74\u001b[0m losses\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, batch_size)\n\u001b[1;32m     75\u001b[0m y_preds \u001b[38;5;241m=\u001b[39m softmax(y_preds)\n\u001b[1;32m     76\u001b[0m preds\u001b[38;5;241m.\u001b[39mappend(y_preds\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()) \n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"valid_folds = train_df[train_df['fold'] == 1].reset_index(drop=True)\n\nvalid_dataset = CustomDataset(valid_folds, config, mode=\"train\")\n\nvalid_loader = DataLoader(valid_dataset,\n                              batch_size=config.BATCH_SIZE_VALID,\n                              shuffle=False,\n                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=False)\n\navg_val_loss, prediction_dict = valid_epoch(valid_loader, model, device)\npredictions = prediction_dict[\"predictions\"]","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:45:22.938552Z","iopub.execute_input":"2024-07-19T03:45:22.939382Z","iopub.status.idle":"2024-07-19T03:45:22.949405Z","shell.execute_reply.started":"2024-07-19T03:45:22.939341Z","shell.execute_reply":"2024-07-19T03:45:22.948338Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"#! zip -r models.zip /kaggle/working/models","metadata":{"execution":{"iopub.status.busy":"2024-07-16T19:22:08.424314Z","iopub.execute_input":"2024-07-16T19:22:08.424893Z","iopub.status.idle":"2024-07-16T19:22:08.428855Z","shell.execute_reply.started":"2024-07-16T19:22:08.424864Z","shell.execute_reply":"2024-07-16T19:22:08.427796Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Score</b><a class='anchor' id='score'></a> [↑](#top) \n\n***","metadata":{"execution":{"iopub.status.busy":"2024-02-15T22:27:03.071166Z","iopub.execute_input":"2024-02-15T22:27:03.071564Z","iopub.status.idle":"2024-02-15T22:27:03.084649Z","shell.execute_reply.started":"2024-02-15T22:27:03.071534Z","shell.execute_reply":"2024-02-15T22:27:03.083623Z"}}},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/kaggle-kl-div')\nfrom kaggle_kl_div import score\n\n# === Pre-process OOF ===\nlabel_cols = label_cols.tolist()\ngt = train_df[[\"eeg_id\"] + label_cols]\ngt.sort_values(by=\"eeg_id\", inplace=True)\ngt.reset_index(inplace=True, drop=True)\n\npreds = oof_df[[\"eeg_id\"] + target_preds]\npreds.columns = [\"eeg_id\"] + label_cols\npreds.sort_values(by=\"eeg_id\", inplace=True)\npreds.reset_index(inplace=True, drop=True)\n\ny_trues = gt[label_cols]\ny_preds = preds[label_cols]\n\noof = pd.DataFrame(y_preds.copy())\noof['id'] = np.arange(len(oof))\n\ntrue = pd.DataFrame(y_trues.copy())\ntrue['id'] = np.arange(len(true))\n\ncv = score(solution=true, submission=oof, row_id_column_name='id')\nprint('CV Score with WaveNet Raw EEG =',cv)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T03:40:53.814461Z","iopub.execute_input":"2024-07-19T03:40:53.815318Z","iopub.status.idle":"2024-07-19T03:40:55.093989Z","shell.execute_reply.started":"2024-07-19T03:40:53.815288Z","shell.execute_reply":"2024-07-19T03:40:55.092846Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_26/3906671217.py:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  gt.sort_values(by=\"eeg_id\", inplace=True)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[40], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m gt\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meeg_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m gt\u001b[38;5;241m.\u001b[39mreset_index(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 11\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43moof_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meeg_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget_preds\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     12\u001b[0m preds\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meeg_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m label_cols\n\u001b[1;32m     13\u001b[0m preds\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meeg_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:3899\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3898\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3899\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3901\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:6115\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6113\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6115\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6117\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6119\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:6176\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6175\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 6176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6178\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6179\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['eeg_id', 'seizure_vote_pred', 'lpd_vote_pred', 'gpd_vote_pred',\\n       'lrda_vote_pred', 'grda_vote_pred', 'other_vote_pred'],\\n      dtype='object')] are in the [columns]\""],"ename":"KeyError","evalue":"\"None of [Index(['eeg_id', 'seizure_vote_pred', 'lpd_vote_pred', 'gpd_vote_pred',\\n       'lrda_vote_pred', 'grda_vote_pred', 'other_vote_pred'],\\n      dtype='object')] are in the [columns]\"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}