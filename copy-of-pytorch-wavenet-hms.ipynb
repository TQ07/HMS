{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"},{"sourceId":7392733,"sourceType":"datasetVersion","datasetId":4297749},{"sourceId":7465251,"sourceType":"datasetVersion","datasetId":4317718}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gc\nimport math\nimport matplotlib.pyplot as plt\nimport multiprocessing\nimport numpy as np\nimport os\nimport pandas as pd\nimport random\nimport time\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom glob import glob\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import OneCycleLR\nfrom tqdm.notebook import tqdm\nfrom typing import Dict, List\n\n\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-09-13T15:01:20.621294Z","iopub.execute_input":"2024-09-13T15:01:20.621653Z","iopub.status.idle":"2024-09-13T15:01:24.929506Z","shell.execute_reply.started":"2024-09-13T15:01:20.621616Z","shell.execute_reply":"2024-09-13T15:01:24.928426Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!mkdir models","metadata":{"execution":{"iopub.status.busy":"2024-09-13T15:01:35.280070Z","iopub.execute_input":"2024-09-13T15:01:35.280607Z","iopub.status.idle":"2024-09-13T15:01:36.390705Z","shell.execute_reply.started":"2024-09-13T15:01:35.280568Z","shell.execute_reply":"2024-09-13T15:01:36.389452Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Configuration</b><a class='anchor' id='configuration'></a> [↑](#top) \n\n***","metadata":{}},{"cell_type":"code","source":"class config:\n    AMP = True\n    TRAIN_VAL_RATIO = 0.95\n    BATCH_SIZE_TRAIN = 7\n    BATCH_SIZE_VALID = 7\n    EPOCHS = 5\n    GRADIENT_ACCUMULATION_STEPS = 4\n    MAX_GRAD_NORM = 1e7\n    NUM_WORKERS = 0 # multiprocessing.cpu_count()\n    PRINT_FREQ = 20\n    SEED = 20\n    TRAIN_FULL_DATA = False\n    VISUALIZE = True\n    WEIGHT_DECAY = 0.01\n    goofy_ahh_var = True \n    \n    \nclass paths:\n    OUTPUT_DIR = \"/kaggle/working/\"\n    TRAIN_CSV = \"/kaggle/input/hms-harmful-brain-activity-classification/train.csv\"\n    TRAIN_EEGS = \"/kaggle/input/hms-harmful-brain-activity-classification/train_eegs/\"","metadata":{"execution":{"iopub.status.busy":"2024-09-13T15:01:49.720562Z","iopub.execute_input":"2024-09-13T15:01:49.721013Z","iopub.status.idle":"2024-09-13T15:01:49.728243Z","shell.execute_reply.started":"2024-09-13T15:01:49.720971Z","shell.execute_reply":"2024-09-13T15:01:49.727147Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Utils</b><a class='anchor' id='utils'></a> [↑](#top) \n\n***\n\nUtility functions.","metadata":{}},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef asMinutes(s: float):\n    \"Convert to minutes.\"\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since: float, percent: float):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\n\ndef eeg_from_parquet(parquet_path: str, display: bool = False) -> np.ndarray:\n    \"\"\"\n    This function reads one parquet file and extracts the middle 50 seconds of readings. Then it fills NaN values\n    with the mean value (ignoring NaNs).\n    :param parquet_path: path to parquet file.\n    :param display: whether to display EEG plots or not.\n    :return data: np.array of shape  (time_steps, eeg_features) -> (10_000, 8)\n    \"\"\"\n    # === Extract middle 50 seconds ===\n    eeg = pd.read_parquet(parquet_path, columns=eeg_features)\n    rows = len(eeg)\n    offset = (rows - 10_000) // 2 # 50 * 200 = 10_000\n    eeg = eeg.iloc[offset:offset+10_000] # middle 50 seconds, has the same amount of readings to left and right\n    if display: \n        plt.figure(figsize=(10,5))\n        offset = 0\n    # === Convert to numpy ===\n    data = np.zeros((10_000, len(eeg_features))) # create placeholder of same shape with zeros\n    for index, feature in enumerate(eeg_features):\n        x = eeg[feature].values.astype('float32') # convert to float32\n        mean = np.nanmean(x) # arithmetic mean along the specified axis, ignoring NaNs\n        nan_percentage = np.isnan(x).mean() # percentage of NaN values in feature\n        # === Fill nan values ===\n        if nan_percentage < 1: # if some values are nan, but not all\n            x = np.nan_to_num(x, nan=mean)\n        else: # if all values are nan\n            x[:] = 0 # convert all nans to zero\n        data[:, index] = x # set the currnet column of the data to the feature\n        if display: \n            if index != 0:\n                offset += x.max()\n            plt.plot(range(10_000), x-offset, label=feature)\n            offset -= x.min()\n    if display:\n        plt.legend()\n        name = parquet_path.split('/')[-1].split('.')[0]\n        plt.yticks([])\n        plt.title(f'EEG {name}',size=16)\n        plt.show()    \n    return data\n    \ndef sep():\n    print(\"-\"*100)\n\n    \ntarget_preds = [x + \"_pred\" for x in ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']]\nlabel_to_num = {'Seizure': 0, 'LPD': 1, 'GPD': 2, 'LRDA': 3, 'GRDA': 4, 'Other':5}\nnum_to_label = {v: k for k, v in label_to_num.items()}","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-13T15:01:50.949151Z","iopub.execute_input":"2024-09-13T15:01:50.949535Z","iopub.status.idle":"2024-09-13T15:01:50.971021Z","shell.execute_reply.started":"2024-09-13T15:01:50.949499Z","shell.execute_reply":"2024-09-13T15:01:50.969877Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Load Data</b><a class='anchor' id='load_data'></a> [↑](#top) \n\n***\n\nLoad the competition's data.","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(paths.TRAIN_CSV)\nlabel_cols = train_df.columns[-6:]\nprint(f\"Train cataframe shape is: {train_df.shape}\")\nprint(f\"Labels: {list(label_cols)}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-13T15:01:52.999118Z","iopub.execute_input":"2024-09-13T15:01:52.999969Z","iopub.status.idle":"2024-09-13T15:01:53.292464Z","shell.execute_reply.started":"2024-09-13T15:01:52.999908Z","shell.execute_reply":"2024-09-13T15:01:53.291464Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Train cataframe shape is: (106800, 15)\nLabels: ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n","output_type":"stream"}]},{"cell_type":"code","source":"# sample eeg\neeg_df = pd.read_parquet(paths.TRAIN_EEGS + \"100261680.parquet\")\neeg_features = eeg_df.columns\nprint(f'There are {len(eeg_features)} raw eeg features')\nprint(list(eeg_features))\neeg_features = ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\nfeature_to_index = {x:y for x,y in zip(eeg_features, range(len(eeg_features)))}","metadata":{"execution":{"iopub.status.busy":"2024-09-13T15:01:54.181543Z","iopub.execute_input":"2024-09-13T15:01:54.182210Z","iopub.status.idle":"2024-09-13T15:01:54.458124Z","shell.execute_reply.started":"2024-09-13T15:01:54.182168Z","shell.execute_reply":"2024-09-13T15:01:54.457111Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"There are 20 raw eeg features\n['Fp1', 'F3', 'C3', 'P3', 'F7', 'T3', 'T5', 'O1', 'Fz', 'Cz', 'Pz', 'Fp2', 'F4', 'C4', 'P4', 'F8', 'T4', 'T6', 'O2', 'EKG']\n","output_type":"stream"}]},{"cell_type":"code","source":"feature_to_index","metadata":{"execution":{"iopub.status.busy":"2024-08-25T01:15:47.836355Z","iopub.execute_input":"2024-08-25T01:15:47.836828Z","iopub.status.idle":"2024-08-25T01:15:47.845139Z","shell.execute_reply.started":"2024-08-25T01:15:47.836782Z","shell.execute_reply":"2024-08-25T01:15:47.843845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eeg_lens = []\n\nfor i, eeg_id in tqdm(enumerate(eeg_ids)):  \n    # Save EEG to Python dictionary of numpy arrays\n    eeg_path = paths.TRAIN_EEGS + str(eeg_id) + \".parquet\"\n    eeg = pd.read_parquet(eeg_path, columns=eeg_features)\n    eeg_lens.append(len(eeg))","metadata":{"execution":{"iopub.status.busy":"2024-08-24T21:44:41.505775Z","iopub.execute_input":"2024-08-24T21:44:41.506277Z","iopub.status.idle":"2024-08-24T21:52:11.766195Z","shell.execute_reply.started":"2024-08-24T21:44:41.506226Z","shell.execute_reply":"2024-08-24T21:52:11.764629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eeg_lens = np.sort(eeg_lens)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T21:53:52.573294Z","iopub.execute_input":"2024-08-24T21:53:52.573805Z","iopub.status.idle":"2024-08-24T21:53:52.582263Z","shell.execute_reply.started":"2024-08-24T21:53:52.573723Z","shell.execute_reply":"2024-08-24T21:53:52.580908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(eeg_lens)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T21:55:39.412658Z","iopub.execute_input":"2024-08-24T21:55:39.413133Z","iopub.status.idle":"2024-08-24T21:55:39.681196Z","shell.execute_reply.started":"2024-08-24T21:55:39.413089Z","shell.execute_reply":"2024-08-24T21:55:39.679931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(eeg_lens, return_counts=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T21:56:37.014595Z","iopub.execute_input":"2024-08-24T21:56:37.015227Z","iopub.status.idle":"2024-08-24T21:56:37.043523Z","shell.execute_reply.started":"2024-08-24T21:56:37.015170Z","shell.execute_reply":"2024-08-24T21:56:37.039971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(eeg_lens)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T21:52:35.373859Z","iopub.execute_input":"2024-08-24T21:52:35.374367Z","iopub.status.idle":"2024-08-24T21:52:35.386590Z","shell.execute_reply.started":"2024-08-24T21:52:35.374321Z","shell.execute_reply":"2024-08-24T21:52:35.385327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nrun this section if data isn't uploaded on the notebook\n'''\nall_eegs = {}\nvisualize = 1\neeg_paths = glob(paths.TRAIN_EEGS + \"*.parquet\")\neeg_ids = train_df.eeg_id.unique()\n\nfor i, eeg_id in tqdm(enumerate(eeg_ids)):  \n    # Save EEG to Python dictionary of numpy arrays\n    eeg_path = paths.TRAIN_EEGS + str(eeg_id) + \".parquet\"\n    data = eeg_from_parquet(eeg_path, display=i<visualize)              \n    all_eegs[eeg_id] = data\n    \n    if i == visualize:\n        print(f'Processing {train_df.eeg_id.nunique()} eeg parquets... ',end='')\n       ","metadata":{"execution":{"iopub.status.busy":"2024-08-24T23:51:41.499471Z","iopub.execute_input":"2024-08-24T23:51:41.499912Z","iopub.status.idle":"2024-08-25T00:00:56.572496Z","shell.execute_reply.started":"2024-08-24T23:51:41.499874Z","shell.execute_reply":"2024-08-25T00:00:56.569886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.save('all_eegs',all_eegs)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T15:03:23.092608Z","iopub.execute_input":"2024-09-13T15:03:23.093538Z","iopub.status.idle":"2024-09-13T15:04:00.542528Z","shell.execute_reply.started":"2024-09-13T15:03:23.093496Z","shell.execute_reply":"2024-09-13T15:04:00.539922Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"all_eegs = np.load('/kaggle/input/brain-eegs/eegs.npy', allow_pickle = True).item()","metadata":{"execution":{"iopub.status.busy":"2024-09-13T15:02:02.470451Z","iopub.execute_input":"2024-09-13T15:02:02.470825Z","iopub.status.idle":"2024-09-13T15:03:23.090726Z","shell.execute_reply.started":"2024-09-13T15:02:02.470788Z","shell.execute_reply":"2024-09-13T15:03:23.089779Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"CREATE_EEGS = False\nvisualize = 1\neeg_paths = glob(paths.TRAIN_EEGS + \"*.parquet\")\neeg_ids = train_df.eeg_id.unique()\neeg_ids","metadata":{"execution":{"iopub.status.busy":"2024-09-13T14:41:53.614474Z","iopub.execute_input":"2024-09-13T14:41:53.615167Z","iopub.status.idle":"2024-09-13T14:41:55.429321Z","shell.execute_reply.started":"2024-09-13T14:41:53.615117Z","shell.execute_reply":"2024-09-13T14:41:55.428278Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"array([1628180742, 2277392603,  722738444, ..., 1850739625, 1306668185,\n        351917269])"},"metadata":{}}]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Data pre-processing</b><a class='anchor' id='preprocessing'></a> [↑](#top) \n\n***","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(paths.TRAIN_CSV)\nlabel_cols = df.columns[-6:]\n\n# the agg('first') function is applied to each group. This function takes the first element of the group\ntrain_df = df.groupby('eeg_id')[['patient_id']].agg('first') # selects unique eeg_ids by using .agg('first'). In that df, the only data is 'patient_id'\naux = df.groupby('eeg_id')[label_cols].agg('sum') # for each eeg_id, sum the label_cols values\n\nfor label in label_cols:\n    train_df[label] = aux[label].values\n    \n    \ny_data = train_df[label_cols].values\ny_data = y_data / y_data.sum(axis=1,keepdims=True)\ntrain_df[label_cols] = y_data\n\naux = df.groupby('eeg_id')[['expert_consensus']].agg('first')\ntrain_df['target'] = aux\n\ntrain_df = train_df.reset_index()\ntrain_df = train_df.loc[train_df.eeg_id.isin(eeg_ids)]\nprint(f\"Train dataframe with unique eeg_id has shape: {train_df.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-13T14:41:55.430627Z","iopub.execute_input":"2024-09-13T14:41:55.431027Z","iopub.status.idle":"2024-09-13T14:41:55.698399Z","shell.execute_reply.started":"2024-09-13T14:41:55.430988Z","shell.execute_reply":"2024-09-13T14:41:55.697268Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Train dataframe with unique eeg_id has shape: (17089, 9)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Butter Low-Pass Filter</b><a class='anchor' id='filter'></a> [↑](#top) \n\n***\n\n- [scipy.signal.butter()][1]\n- [scipy.signal.lfilter()][2]\n\n[1]: https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.butter.html#scipy.signal.butter\n[2]: https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.lfilter.html#scipy.signal.lfilter","metadata":{}},{"cell_type":"code","source":"from scipy.signal import butter, lfilter\n\ndef butter_lowpass_filter(data, cutoff_freq: int = 8, sampling_rate: int = 200, order: int = 4):\n    nyquist = 0.5 * sampling_rate\n    normal_cutoff = cutoff_freq / nyquist\n    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n    filtered_data = lfilter(b, a, data, axis=0)\n    return filtered_data","metadata":{"execution":{"iopub.status.busy":"2024-09-13T14:41:55.701013Z","iopub.execute_input":"2024-09-13T14:41:55.701426Z","iopub.status.idle":"2024-09-13T14:41:56.240169Z","shell.execute_reply.started":"2024-09-13T14:41:55.701378Z","shell.execute_reply":"2024-09-13T14:41:56.239260Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## <b><span style='color:#F1A424'>Visualize</span></b>\n","metadata":{}},{"cell_type":"code","source":"frequencies = [1,2,4,8,16,20][::-1] # frequencies in Hz\nx = [all_eegs[eeg_ids[0]][:,0]] # select one EEG feature\n\nfor frequency in frequencies:\n    x.append(butter_lowpass_filter(x[0], cutoff_freq=frequency))\n\nplt.figure(figsize=(12,8))\nplt.plot(range(10_000), x[0], label='without filter')\nfor k in range(1,len(x)):\n    plt.plot(range(10_000),x[k]-k*(x[0].max()-x[0].min()), label=f'with filter {frequencies[k-1]}Hz')\n\nplt.legend()\nplt.yticks([])\nplt.title('Butter Low-Pass Filter Examples',size=18)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T00:59:08.304467Z","iopub.execute_input":"2024-08-25T00:59:08.305075Z","iopub.status.idle":"2024-08-25T00:59:09.337359Z","shell.execute_reply.started":"2024-08-25T00:59:08.305026Z","shell.execute_reply":"2024-08-25T00:59:09.335860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset ","metadata":{"execution":{"iopub.status.busy":"2024-08-25T00:42:07.675055Z","iopub.execute_input":"2024-08-25T00:42:07.675638Z","iopub.status.idle":"2024-08-25T00:42:07.681791Z","shell.execute_reply.started":"2024-08-25T00:42:07.675583Z","shell.execute_reply":"2024-08-25T00:42:07.680418Z"}}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(\n        self, df: pd.DataFrame, config, mode: str = 'train',\n        eegs: Dict[int, np.ndarray] = all_eegs, downsample: int = 10, \n    ): \n        self.df = df\n        self.config = config\n        self.batch_size = self.config.BATCH_SIZE_TRAIN\n        self.mode = mode\n        self.eegs = eegs\n        self.downsample = downsample\n        \n    def __len__(self):\n        \"\"\"\n        Length of dataset.\n        \"\"\"\n        return len(self.df)\n        \n    def __getitem__(self, index):\n        \"\"\"\n        Get one item.\n        \"\"\"\n        X, y = self.__data_generation(index)\n        \n     \n        \n        X = X[np.random.randint(low=0, high=self.downsample)::self.downsample,:] # used to scaled down 10000 samples to 2000 samples by taking every 5th row\n        # that was sequence[start:stop:step]\n        if self.mode == 'pretrain':\n            y = y[np.random.randint(low=0, high=self.downsample)::self.downsample,:]\n        \n        output = {\n            \"X\": torch.tensor(X, dtype=torch.float32),\n            \"y\": torch.tensor(y, dtype=torch.float32)\n        }\n        return output\n                        \n    def __data_generation(self, index):\n        row = self.df.iloc[index] # select a random eeg from 17000 unique eegs\n        X = np.zeros((10_000, 8), dtype='float32')\n        \n        if self.mode == 'pretrain':\n            y = np.zeros((int(10000/self.downsample), 8), dtype='float32') # may need further modifications if not using 10000\n        if self.mode == 'train':\n            y = np.zeros(6, dtype='float32')\n        data = self.eegs[row.eeg_id] # get the eeg\n\n        # === Feature engineering ===\n        X[:,0] = data[:,feature_to_index['Fp1']] - data[:,feature_to_index['T3']]\n        X[:,1] = data[:,feature_to_index['T3']] - data[:,feature_to_index['O1']]\n\n        X[:,2] = data[:,feature_to_index['Fp1']] - data[:,feature_to_index['C3']]\n        X[:,3] = data[:,feature_to_index['C3']] - data[:,feature_to_index['O1']]\n\n        X[:,4] = data[:,feature_to_index['Fp2']] - data[:,feature_to_index['C4']]\n        X[:,5] = data[:,feature_to_index['C4']] - data[:,feature_to_index['O2']]\n\n        X[:,6] = data[:,feature_to_index['Fp2']] - data[:,feature_to_index['T4']]\n        X[:,7] = data[:,feature_to_index['T4']] - data[:,feature_to_index['O2']]\n\n        # === Standarize === but why these values??\n        X = np.clip(X,-1024, 1024)\n        X = np.nan_to_num(X, nan=0) / 32.0\n\n        # === Butter Low-pass Filter ===\n        X = butter_lowpass_filter(X)\n        \n        if self.mode == 'train':\n            y = row[label_cols].values.astype(np.float32)\n        if self.mode == 'pretrain':\n            y = X\n            \n        return X, y","metadata":{"execution":{"iopub.status.busy":"2024-09-13T14:45:25.839646Z","iopub.execute_input":"2024-09-13T14:45:25.840364Z","iopub.status.idle":"2024-09-13T14:45:25.856951Z","shell.execute_reply.started":"2024-09-13T14:45:25.840324Z","shell.execute_reply":"2024-09-13T14:45:25.856054Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> DataLoader</b><a class='anchor' id='dataloader'></a> [↑](#top) \n\n***","metadata":{}},{"cell_type":"code","source":"train_dataset = CustomDataset(train_df, config, mode=\"pretrain\")\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=config.BATCH_SIZE_TRAIN,\n    shuffle=False,\n    num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True\n)\noutput = train_dataset[0]\nX, y = output[\"X\"], output[\"y\"]\nprint(f\"X shape: {X.shape}\")\nprint(f\"y shape: {y.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-13T14:45:26.742833Z","iopub.execute_input":"2024-09-13T14:45:26.743447Z","iopub.status.idle":"2024-09-13T14:45:26.801369Z","shell.execute_reply.started":"2024-09-13T14:45:26.743409Z","shell.execute_reply":"2024-09-13T14:45:26.800474Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"X shape: torch.Size([1000, 8])\ny shape: torch.Size([1000, 8])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Fine-tune Model code","metadata":{}},{"cell_type":"code","source":"from torch import nn, Tensor\nfrom torch.nn import TransformerEncoder, TransformerEncoderLayer\nfrom torchinfo import summary\n\nclass eegEncoder(nn.Module):\n\n\n    def __init__(self,d_model, nhead,  nlayers, nclasses, d_hid, dropout=0.1):\n        super(eegEncoder, self).__init__()\n        self.d_model = d_model\n        self.input_projection = nn.Linear(8, d_model) # (n_chhannels, d_model)  \n        self.linear = nn.Linear(d_model, nclasses)\n\n        \n        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout, batch_first=True, norm_first =False) # set batch_first = True b/c input is of shape (b, T, C)!!!!!!!\n        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n    \n    def pos_encode(self, encoding_1):\n        pe = torch.ones_like(encoding_1[0])\n        position = torch.arange(0, 1000).unsqueeze(-1)\n        temp = torch.Tensor(range(0, self.d_model, 2))\n        temp = temp * -(math.log(10000) / self.d_model)\n        temp = torch.exp(temp).unsqueeze(0)\n        temp = torch.matmul(position.float(), temp)  # shape:[input, d_model/2]\n        pe[:, 0::2] = torch.sin(temp)\n        pe[:, 1::2] = torch.cos(temp)\n\n        encoding_1 = encoding_1 + pe\n        return encoding_1\n\n    def forward(self, src):\n        \n        B, T, C = src.shape #where B = batch_size, T = time_step, C = n_classes\n        \n        input_proj = self.input_projection(src) #output is shape (B, T, d_model)\n        input_pos = self.pos_encode(input_proj)#self.position_embedding_table(torch.arange(T, device=src.device))  # (T, n_embd)\n        \n        output_1 = self.transformer_encoder(input_pos) #output_1 is shape of (B,T, )\n    \n        #print(output_1.shape)\n        \n        output_2 = torch.mean(output_1, axis=1) #average over sequence length dimension. Output is shape (B,)\n        output_2 = self.linear(output_2)\n        return output_2\n\n# def __init__(self,d_model, nhead,  nlayers, nclasses, d_hid, dropout=0.1):\nmodel = eegEncoder(d_model = 640, nhead= 8, nlayers= 10, nclasses = 6, d_hid=1024)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T14:45:40.743890Z","iopub.execute_input":"2024-09-13T14:45:40.744746Z","iopub.status.idle":"2024-09-13T14:45:40.925743Z","shell.execute_reply.started":"2024-09-13T14:45:40.744693Z","shell.execute_reply":"2024-09-13T14:45:40.924466Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Pre-train model code ","metadata":{}},{"cell_type":"code","source":"'''\nobjective 1: \npredict next time step value for eeg \n\nobjective 2:\npredict current time step value of eeg from spectrogram \n\n\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import nn, Tensor\nfrom torch.nn import TransformerEncoder, TransformerEncoderLayer\nfrom torchinfo import summary\n\nclass eegEncoder(nn.Module):\n    \n    def __init__(self,d_model, nhead,  nlayers, nclasses, d_hid, dropout=0.1):\n        super(eegEncoder, self).__init__()\n        self.d_model = d_model\n        self.input_projection = nn.Linear(8, d_model) # (n_chhannels, d_model)  \n        self.linear = nn.Linear(d_model, nclasses)\n\n        \n        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout, batch_first=True, norm_first =False) # set batch_first = True b/c input is of shape (b, T, C)!!!!!!!\n        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n    \n    def pos_encode(self, encoding_1):\n        pe = torch.ones_like(encoding_1[0])\n        position = torch.arange(0, 2000).unsqueeze(-1)\n        temp = torch.Tensor(range(0, self.d_model, 2))\n        temp = temp * -(math.log(10000) / self.d_model)\n        temp = torch.exp(temp).unsqueeze(0)\n        temp = torch.matmul(position.float(), temp)  # shape:[input, d_model/2]\n        pe[:, 0::2] = torch.sin(temp)\n        pe[:, 1::2] = torch.cos(temp)\n\n        encoding_1 = encoding_1 + pe\n        return encoding_1\n\n    def forward(self, src):\n        \n        B, T, C = src.shape #where B = batch_size, T = time_step, C = n_classes\n        \n        input_proj = self.input_projection(src) #output is shape (B, T, d_model)\n        input_pos = self.pos_encode(input_proj)#self.position_embedding_table(torch.arange(T, device=src.device))  # (T, n_embd)\n        \n        output_1 = self.transformer_encoder(input_pos) #output_1 is shape of (B,T, )\n    \n        #print(output_1.shape)\n        \n        #output_2 = torch.mean(output_1, axis=1) #average over sequence length dimension. Output is shape (B,)\n        output_2 = self.linear(output_1) # outputs should be of size (B, T, C)\n        return output_2 \n\n# def __init__(self,d_model, nhead,  nlayers, nclasses, d_hid, dropout=0.1):\nmodel = eegEncoder(d_model = 640, nhead= 8, nlayers= 10, nclasses = 6, d_hid=1024)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T14:45:50.870624Z","iopub.execute_input":"2024-09-13T14:45:50.871311Z","iopub.status.idle":"2024-09-13T14:45:50.960248Z","shell.execute_reply.started":"2024-09-13T14:45:50.871269Z","shell.execute_reply":"2024-09-13T14:45:50.959254Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T14:55:10.735725Z","iopub.execute_input":"2024-09-13T14:55:10.736132Z","iopub.status.idle":"2024-09-13T14:55:11.122840Z","shell.execute_reply.started":"2024-09-13T14:55:10.736091Z","shell.execute_reply":"2024-09-13T14:55:11.121482Z"},"trusted":true},"execution_count":32,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1138\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move and/or cast the parameters and buffers.\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \n\u001b[1;32m   1055\u001b[0m \u001b[38;5;124;03m    This can be called as\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \n\u001b[1;32m   1137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1138\u001b[0m     device, dtype, non_blocking, convert_to_format \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_to\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (dtype\u001b[38;5;241m.\u001b[39mis_floating_point \u001b[38;5;129;01mor\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mis_complex):\n","\u001b[0;31mTypeError\u001b[0m: to() received an invalid combination of arguments - got (property), but expected one of:\n * (torch.device device = None, torch.dtype dtype = None, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)\n * (torch.dtype dtype, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)\n * (Tensor tensor, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)\n"],"ename":"TypeError","evalue":"to() received an invalid combination of arguments - got (property), but expected one of:\n * (torch.device device = None, torch.dtype dtype = None, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)\n * (torch.dtype dtype, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)\n * (Tensor tensor, bool non_blocking = False, bool copy = False, *, torch.memory_format memory_format = None)\n","output_type":"error"}]},{"cell_type":"code","source":"summary(model)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T14:45:53.519618Z","iopub.execute_input":"2024-09-13T14:45:53.520690Z","iopub.status.idle":"2024-09-13T14:45:53.539866Z","shell.execute_reply.started":"2024-09-13T14:45:53.520644Z","shell.execute_reply":"2024-09-13T14:45:53.538750Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                                            Param #\n==========================================================================================\neegEncoder                                                        --\n├─Linear: 1-1                                                     5,760\n├─Linear: 1-2                                                     3,846\n├─TransformerEncoder: 1-3                                         --\n│    └─ModuleList: 2-1                                            --\n│    │    └─TransformerEncoderLayer: 3-1                          2,955,904\n│    │    └─TransformerEncoderLayer: 3-2                          2,955,904\n│    │    └─TransformerEncoderLayer: 3-3                          2,955,904\n│    │    └─TransformerEncoderLayer: 3-4                          2,955,904\n│    │    └─TransformerEncoderLayer: 3-5                          2,955,904\n│    │    └─TransformerEncoderLayer: 3-6                          2,955,904\n│    │    └─TransformerEncoderLayer: 3-7                          2,955,904\n│    │    └─TransformerEncoderLayer: 3-8                          2,955,904\n│    │    └─TransformerEncoderLayer: 3-9                          2,955,904\n│    │    └─TransformerEncoderLayer: 3-10                         2,955,904\n==========================================================================================\nTotal params: 29,568,646\nTrainable params: 29,568,646\nNon-trainable params: 0\n=========================================================================================="},"metadata":{}}]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Train and Validation Functions</b><a class='anchor' id='functions'></a> [↑](#top) \n\n***","metadata":{}},{"cell_type":"code","source":"'''\npretrain training loop modifications:\n\ninputs are the same, labels are the next 1000 step inputs \n\n\n'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RMSELoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.mse = nn.MSELoss()\n        \n    def forward(self,yhat,y):\n        return torch.sqrt(self.mse(yhat,y))","metadata":{"execution":{"iopub.status.busy":"2024-09-13T14:46:08.127316Z","iopub.execute_input":"2024-09-13T14:46:08.128134Z","iopub.status.idle":"2024-09-13T14:46:08.134377Z","shell.execute_reply.started":"2024-09-13T14:46:08.128085Z","shell.execute_reply":"2024-09-13T14:46:08.133382Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def train_epoch(train_loader, model, optimizer, epoch, scheduler, device, criterion, pretrain=False):\n    \"\"\"One epoch training pass.\"\"\"\n    model.train()\n    scaler = torch.amp.GradScaler(enabled=config.AMP) \n    losses = AverageMeter()\n    start = end = time.time()\n    global_step = 0\n    \n    # ========== ITERATE OVER TRAIN BATCHES ============\n    with tqdm(train_loader, unit=\"train_batch\", desc='Train') as tqdm_train_loader:\n        for step, batch in enumerate(tqdm_train_loader):\n            X = batch.pop(\"X\").to(device) # send inputs to `device`\n            y = batch.pop(\"y\").to(device) # send labels to `device`\n            batch_size = y.size(0)\n            \n            with torch.autocast(device_type='cuda', dtype=torch.float16):\n                y_preds = model(X)\n                \n                if not pretrain:\n                    loss = criterion(F.log_softmax(y_preds, dim=1), y)\n                    \n                if pretrain:\n                    loss = criterion(y_preds, y)\n                \n                \n            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n                \n            losses.update(loss.item(), batch_size)\n            scaler.scale(loss).backward()\n            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.MAX_GRAD_NORM)\n            \n            if (step + 1) % config.GRADIENT_ACCUMULATION_STEPS == 0:\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n                global_step += 1\n                scheduler.step()\n            end = time.time()\n\n            # ========== LOG INFO ==========\n            if step % config.PRINT_FREQ == 0 or step == (len(train_loader)-1):\n                print('Epoch: [{0}][{1}/{2}] '\n                      'Elapsed {remain:s} '\n                      'Loss: {loss.avg:.4f} '\n                      'Grad: {grad_norm:.4f}  '\n                      'LR: {lr:.8f}  '\n                      .format(epoch+1, step, len(train_loader), \n                              remain=timeSince(start, float(step+1)/len(train_loader)),\n                              loss=losses,\n                              grad_norm=grad_norm,\n                              lr=scheduler.get_last_lr()[0]))\n                \n            tqdm_train_loader.set_postfix(loss=loss.item())        \n\n    return losses.avg\n\n\ndef valid_epoch(valid_loader, model, device):\n    model.eval() \n    softmax = nn.Softmax(dim=1)\n    losses = AverageMeter()\n    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n    prediction_dict = {}\n    preds = []\n    start = end = time.time()\n    with tqdm(valid_loader, unit=\"valid_batch\", desc='Validation') as tqdm_valid_loader:\n        for step, batch in enumerate(tqdm_valid_loader):\n            X = batch.pop(\"X\").to(device) \n            y = batch.pop(\"y\").to(device)\n            batch_size = y.size(0)\n            with torch.no_grad():\n                y_preds = model(X)\n                \n                \n                if pretrain:\n                    loss = criterion(y_preds, y)\n                else:\n                    loss = criterion(F.log_softmax(y_preds, dim=1), y)\n                \n                \n            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n            losses.update(loss.item(), batch_size)\n            y_preds = softmax(y_preds)\n            preds.append(y_preds.to('cpu').numpy()) \n            end = time.time()\n\n            # ========== LOG INFO ==========\n            if step % config.PRINT_FREQ == 0 or step == (len(valid_loader)-1):\n                print('EVAL: [{0}/{1}] '\n                      'Elapsed {remain:s} '\n                      'Loss: {loss.avg:.4f} '\n                      .format(step, len(valid_loader),\n                              remain=timeSince(start, float(step+1)/len(valid_loader)),\n                              loss=losses))\n                \n            tqdm_valid_loader.set_postfix(loss=loss.item())    \n    if pretrain: \n        prediction_dict[\"predictions\"] = 0\n        \n    prediction_dict[\"predictions\"] = np.concatenate(preds)\n    return losses.avg, prediction_dict","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Train Loop</b><a class='anchor' id='train_loop'></a> [↑](#top) \n\n***","metadata":{}},{"cell_type":"code","source":"def train_loop(df, pretrain=False):\n    \n\n    # ======== SPLIT ==========\n    split_len = int(len(df) * config.TRAIN_VAL_RATIO)\n    train_data = df[:split_len]\n    val_data = df[split_len:]\n    \n    # ======== DATASETS ==========\n    train_dataset = CustomDataset(train_data, config, mode=\"pretrain\")\n    val_dataset = CustomDataset(val_data, config, mode=\"pretrain\")\n    \n    # ======== DATALOADERS ==========\n    train_loader = DataLoader(train_dataset,\n                              batch_size=config.BATCH_SIZE_TRAIN,\n                              shuffle=True,\n                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(val_dataset,\n                              batch_size=config.BATCH_SIZE_VALID,\n                              shuffle=False,\n                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=False)\n    \n    # ======== MODEL ==========\n   # model = eegEncoder()\n   # model.to(device)\n\n    optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=config.WEIGHT_DECAY)\n    scheduler = OneCycleLR(\n        optimizer,\n        max_lr=1e-3,\n        epochs=config.EPOCHS,\n        steps_per_epoch=len(train_loader),\n        pct_start=0.1,\n        anneal_strategy=\"cos\",\n        final_div_factor=100,\n    )\n\n    # ======= LOSS ==========\n    if pretrain:\n        criterion = RMSELoss()\n    else:\n        criterion = nn.KLDivLoss(reduction=\"batchmean\")\n    \n    best_loss = np.inf\n    # ====== ITERATE EPOCHS ========\n    for epoch in range(config.EPOCHS):\n        start_time = time.time()\n\n        # ======= TRAIN ==========\n        avg_train_loss = train_epoch(train_loader, model, optimizer, epoch, scheduler, device, criterion, pretrain=pretrain)\n\n        # ======= EVALUATION ==========\n        avg_val_loss, prediction_dict = valid_epoch(valid_loader, model, device, pretrain=pretrain)\n        predictions = prediction_dict[\"predictions\"]\n        \n        # ======= SCORING ==========\n        elapsed = time.time() - start_time\n\n        print(f'Epoch {epoch+1} - avg_train_loss: {avg_train_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        \n        if avg_val_loss < best_loss:\n            best_loss = avg_val_loss\n            print(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n            torch.save({'model': model.state_dict(),\n                        'predictions': predictions},\n                         f\"/kaggle/working/models/eegEncoder_best.pth\")\n\n    predictions = torch.load(f\"/kaggle/working/models/eegEncoder_best.pth\", \n                             map_location=torch.device('cpu'))['predictions']\n    val_data[target_preds] = predictions\n\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    return val_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, model, train_data, val_data, optimizer, scheduler, gpu_id: int, max_epochs):\n        self.gpu_id = gpu_id\n        self.model = model.to(gpu_id)\n        self.train_data = train_data\n        self.optimizer = optimizer\n        self.scheduler = scheduler \n        self.save_every = save_every\n        self.model = DDP(model, device_ids=[gpu_id])\n        self.max_epochs = max_epochs\n        \n        self.criterion = nn.KLDivLoss(reduction=\"batchmean\")\n        self.scaler = torch.amp.GradScaler(enabled=config.AMP) \n\n\n    def _run_train_batch(self, source, targets):\n        self.optimizer.zero_grad()\n        output = self.model(source)\n        loss = F.cross_entropy(output, targets)\n        loss.backward()\n        self.optimizer.step()\n    \n    @torch.no_grad()\n    def _run_val_batch(self, source, targets):\n        output = self.model(source)\n        loss = F.cross_entropy(output, targets)\n\n    def _run_epoch(self, epoch):\n        b_sz = len(next(iter(self.train_data))[0])\n        print(f\"[GPU{self.gpu_id}] Epoch {epoch} | Batchsize: {b_sz} | Steps: {len(self.train_data)}\")\n        self.train_data.sampler.set_epoch(epoch)\n        \n        for source, targets in self.train_data:\n            source = source.to(self.gpu_id)\n            targets = targets.to(self.gpu_id)\n            self._run_batch(source, targets)\n    \n    def train_epoch(self, epoch):\n        \"\"\"One epoch training pass.\"\"\"\n        self.model.train()  \n            \n        losses = AverageMeter()\n        start = end = time.time()\n\n\n        # ========== ITERATE OVER TRAIN BATCHES ============\n        with tqdm(self.train_loader, unit=\"train_batch\", desc='Train') as tqdm_train_loader:\n            for step, batch in enumerate(tqdm_train_loader):\n                X = batch.pop(\"X\").to(self.gpu_id) # send inputs to `device`\n                y = batch.pop(\"y\").to(self.gpu_id) # send labels to `device`\n                batch_size = y.size(0)\n\n                with torch.autocast(device_type='cuda', dtype=torch.float16):\n                    y_preds = model(X)\n                    loss = criterion(F.log_softmax(y_preds, dim=1), y)\n                if config.GRADIENT_ACCUMULATION_STEPS > 1:\n                    loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n\n                losses.update(loss.item(), batch_size)\n                scaler.scale(loss).backward()\n                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.MAX_GRAD_NORM)\n\n                if (step + 1) % config.GRADIENT_ACCUMULATION_STEPS == 0:\n                    scaler.step(optimizer)\n                    scaler.update()\n                    optimizer.zero_grad()\n                    scheduler.step()\n                end = time.time()\n\n                # ========== LOG INFO ==========\n                if step % config.PRINT_FREQ == 0 or step == (len(train_loader)-1):\n                    print('Epoch: [{0}][{1}/{2}] '\n                          'Elapsed {remain:s} '\n                          'Loss: {loss.avg:.4f} '\n                          'Grad: {grad_norm:.4f}  '\n                          'LR: {lr:.8f}  '\n                          .format(epoch+1, step, len(train_loader), \n                                  remain=timeSince(start, float(step+1)/len(train_loader)),\n                                  loss=losses,\n                                  grad_norm=grad_norm,\n                                  lr=scheduler.get_last_lr()[0]))\n\n                tqdm_train_loader.set_postfix(loss=loss.item())        \n\n        return losses.avg\n\n\n    def _save_checkpoint(self, epoch):\n        ckp = self.model.module.state_dict()\n        PATH = \"checkpoint.pt\"\n        torch.save(ckp, PATH)\n        print(f\"Epoch {epoch} | Training checkpoint saved at {PATH}\")\n\n    def train_loop(self, max_epochs):\n        for epoch in range(max_epochs):\n            self.train_epoch(epoch)\n            if self.gpu_id == 0 and epoch % self.save_every == 0:\n                self._save_checkpoint(epoch)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T21:37:22.690895Z","iopub.execute_input":"2024-08-26T21:37:22.691268Z","iopub.status.idle":"2024-08-26T21:37:22.711779Z","shell.execute_reply.started":"2024-08-26T21:37:22.691235Z","shell.execute_reply":"2024-08-26T21:37:22.710729Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Train</b><a class='anchor' id='train'></a> [↑](#top) \n\n***","metadata":{}},{"cell_type":"code","source":"args = (train_df, True )\noof_df = train_loop(args) \noof_df = oof_df.reset_index(drop=True)\noof_df.to_csv('/kaggle/working/models/oof_df.csv', index=False)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-09-13T14:46:45.161108Z","iopub.execute_input":"2024-09-13T14:46:45.161846Z","iopub.status.idle":"2024-09-13T14:46:46.120842Z","shell.execute_reply.started":"2024-09-13T14:46:45.161805Z","shell.execute_reply":"2024-09-13T14:46:46.119280Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Launching training on 2 GPUs.\n","output_type":"stream"},{"name":"stderr","text":"W0913 14:46:45.987000 140062917281600 torch/multiprocessing/spawn.py:146] Terminating process 245 via signal SIGTERM\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702] failed (exitcode: 1) local_rank: 0 (pid: 241) of fn: train_loop (start_method: fork)\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702] Traceback (most recent call last):\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]   File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 659, in _poll\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]     self._pc.join(-1)\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]   File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 189, in join\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]     raise ProcessRaisedException(msg, error_index, failed_process.pid)\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702] torch.multiprocessing.spawn.ProcessRaisedException: \nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702] \nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702] -- Process 0 terminated with the following error:\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702] Traceback (most recent call last):\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]   File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 76, in _wrap\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]     fn(i, *args)\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]   File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 583, in _wrap\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]     ret = record(fn)(*args_)\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]   File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 348, in wrapper\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]     return f(*args, **kwargs)\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]   File \"/tmp/ipykernel_36/493372239.py\", line 13, in train_loop\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]     accelerator = Accelerator(mixed_precision='fp16', gradient_accumulation_steps=4)\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]   File \"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py\", line 383, in __init__\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]     self.state = AcceleratorState(\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]   File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 846, in __init__\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]     PartialState(cpu, **kwargs)\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]   File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 275, in __init__\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]     self.set_device()\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]   File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 786, in set_device\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]     device_module.set_device(self.device)\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]   File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 420, in set_device\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]     torch._C._cuda_setDevice(device)\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]   File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 300, in _lazy_init\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702]     raise RuntimeError(\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702] RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\nE0913 14:46:46.020000 140062917281600 torch/distributed/elastic/multiprocessing/api.py:702] \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mChildFailedError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m args \u001b[38;5;241m=\u001b[39m (train_df, \u001b[38;5;28;01mTrue\u001b[39;00m )\n\u001b[0;32m----> 2\u001b[0m oof_df \u001b[38;5;241m=\u001b[39m \u001b[43mnotebook_launcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m oof_df \u001b[38;5;241m=\u001b[39m oof_df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m oof_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/models/oof_df.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/launchers.py:245\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, mixed_precision, use_port, master_addr, node_rank, num_nodes, rdzv_backend, rdzv_endpoint, rdzv_conf, rdzv_id, max_restarts, monitor_interval, log_line_prefix_template)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;124m\"\u001b[39m, ELASTIC_LOG_LINE_PREFIX_TEMPLATE_PYTORCH_VERSION):\n\u001b[1;32m    244\u001b[0m         launch_config_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_line_prefix_template\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m log_line_prefix_template\n\u001b[0;32m--> 245\u001b[0m     \u001b[43melastic_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLaunchConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlaunch_config_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentrypoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProcessRaisedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py:133\u001b[0m, in \u001b[0;36melastic_launch.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlaunch_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_entrypoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py:264\u001b[0m, in \u001b[0;36mlaunch_agent\u001b[0;34m(config, entrypoint, args)\u001b[0m\n\u001b[1;32m    257\u001b[0m     events\u001b[38;5;241m.\u001b[39mrecord(agent\u001b[38;5;241m.\u001b[39mget_event_succeeded())\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mis_failed():\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;66;03m# ChildFailedError is treated specially by @record\u001b[39;00m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;66;03m# if the error files for the failed children exist\u001b[39;00m\n\u001b[1;32m    262\u001b[0m         \u001b[38;5;66;03m# @record will copy the first error (root cause)\u001b[39;00m\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;66;03m# to the error file of the launcher process.\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChildFailedError(\n\u001b[1;32m    265\u001b[0m             name\u001b[38;5;241m=\u001b[39mentrypoint_name,\n\u001b[1;32m    266\u001b[0m             failures\u001b[38;5;241m=\u001b[39mresult\u001b[38;5;241m.\u001b[39mfailures,\n\u001b[1;32m    267\u001b[0m         )\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreturn_values\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ChildFailedError:\n","\u001b[0;31mChildFailedError\u001b[0m: \n============================================================\ntrain_loop FAILED\n------------------------------------------------------------\nFailures:\n  <NO_OTHER_FAILURES>\n------------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2024-09-13_14:46:45\n  host      : 2e8ab1a26963\n  rank      : 0 (local_rank: 0)\n  exitcode  : 1 (pid: 241)\n  error_file: /tmp/torchelastic_h_zoig_d/none_jl99ltah/attempt_0/0/error.json\n  traceback : Traceback (most recent call last):\n    File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 348, in wrapper\n      return f(*args, **kwargs)\n    File \"/tmp/ipykernel_36/493372239.py\", line 13, in train_loop\n      accelerator = Accelerator(mixed_precision='fp16', gradient_accumulation_steps=4)\n    File \"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py\", line 383, in __init__\n      self.state = AcceleratorState(\n    File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 846, in __init__\n      PartialState(cpu, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 275, in __init__\n      self.set_device()\n    File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 786, in set_device\n      device_module.set_device(self.device)\n    File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 420, in set_device\n      torch._C._cuda_setDevice(device)\n    File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 300, in _lazy_init\n      raise RuntimeError(\n  RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n  \n============================================================"],"ename":"ChildFailedError","evalue":"\n============================================================\ntrain_loop FAILED\n------------------------------------------------------------\nFailures:\n  <NO_OTHER_FAILURES>\n------------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2024-09-13_14:46:45\n  host      : 2e8ab1a26963\n  rank      : 0 (local_rank: 0)\n  exitcode  : 1 (pid: 241)\n  error_file: /tmp/torchelastic_h_zoig_d/none_jl99ltah/attempt_0/0/error.json\n  traceback : Traceback (most recent call last):\n    File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 348, in wrapper\n      return f(*args, **kwargs)\n    File \"/tmp/ipykernel_36/493372239.py\", line 13, in train_loop\n      accelerator = Accelerator(mixed_precision='fp16', gradient_accumulation_steps=4)\n    File \"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py\", line 383, in __init__\n      self.state = AcceleratorState(\n    File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 846, in __init__\n      PartialState(cpu, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 275, in __init__\n      self.set_device()\n    File \"/opt/conda/lib/python3.10/site-packages/accelerate/state.py\", line 786, in set_device\n      device_module.set_device(self.device)\n    File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 420, in set_device\n      torch._C._cuda_setDevice(device)\n    File \"/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 300, in _lazy_init\n      raise RuntimeError(\n  RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method\n  \n============================================================","output_type":"error"}]},{"cell_type":"code","source":"#! zip -r models.zip /kaggle/working/models","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Val ","metadata":{}},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Score</b><a class='anchor' id='score'></a> [↑](#top) \n\n***","metadata":{"execution":{"iopub.status.busy":"2024-02-15T22:27:03.071166Z","iopub.execute_input":"2024-02-15T22:27:03.071564Z","iopub.status.idle":"2024-02-15T22:27:03.084649Z","shell.execute_reply.started":"2024-02-15T22:27:03.071534Z","shell.execute_reply":"2024-02-15T22:27:03.083623Z"}}},{"cell_type":"code","source":"# import sys\n# sys.path.append('/kaggle/input/kaggle-kl-div')\n# from kaggle_kl_div import score\n\n# # === Pre-process OOF ===\n# label_cols = label_cols.tolist()\n# gt = train_df[[\"eeg_id\"] + label_cols]\n# gt.sort_values(by=\"eeg_id\", inplace=True)\n# gt.reset_index(inplace=True, drop=True)\n\n# preds = oof_df[[\"eeg_id\"] + target_preds]\n# preds.columns = [\"eeg_id\"] + label_cols\n# preds.sort_values(by=\"eeg_id\", inplace=True)\n# preds.reset_index(inplace=True, drop=True)\n\n# y_trues = gt[label_cols]\n# y_preds = preds[label_cols]\n\n# oof = pd.DataFrame(y_preds.copy())\n# oof['id'] = np.arange(len(oof))\n\n# true = pd.DataFrame(y_trues.copy())\n# true['id'] = np.arange(len(true))\n\n# cv = score(solution=true, submission=oof, row_id_column_name='id')\n# print('CV Score with WaveNet Raw EEG =',cv)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}